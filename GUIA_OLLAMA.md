# ğŸ¦™ Guia Ollama com Agno

## ğŸ¯ VisÃ£o Geral

Este guia mostra como usar o **Ollama** com o **Agno Framework** para criar agentes de pesquisa com o modelo `deepseek-r1:1.5b` e ferramentas DuckDuckGo.

## ğŸ“‹ PrÃ©-requisitos

### 1. **Servidor Ollama**

- Servidor Ollama rodando em: `matrix.o2pos.com.br:11434`
- Modelo `deepseek-r1:1.5b` disponÃ­vel no servidor

### 2. **DependÃªncias Python**

```bash
pip install agno requests duckduckgo-search
```

## ğŸš€ ConfiguraÃ§Ã£o

### 1. **Testar ConexÃ£o**

Execute o script de teste para verificar se tudo estÃ¡ funcionando:

```bash
python test_ollama.py
```

### 2. **Iniciar Playground**

Para usar os agentes Ollama:

```bash
python playground_ollama.py
```

## ğŸ¤– Agentes DisponÃ­veis

### 1. **Ollama Researcher Agent**

- **FunÃ§Ã£o**: Assistente de pesquisa especializado
- **Ferramentas**: DuckDuckGo Search
- **CaracterÃ­sticas**:
  - Busca informaÃ§Ãµes atualizadas
  - Inclui fontes e referÃªncias
  - Respostas em portuguÃªs brasileiro
  - FormataÃ§Ã£o markdown

### 2. **Ollama Analysis Agent**

- **FunÃ§Ã£o**: Especialista em anÃ¡lise e interpretaÃ§Ã£o
- **Ferramentas**: DuckDuckGo Search
- **CaracterÃ­sticas**:
  - AnÃ¡lises detalhadas e estruturadas
  - MÃºltiplas perspectivas
  - Uso de tabelas e listas
  - Coleta de dados relevantes

### 3. **Ollama News Agent**

- **FunÃ§Ã£o**: RepÃ³rter especializado em notÃ­cias
- **Ferramentas**: DuckDuckGo Search
- **CaracterÃ­sticas**:
  - InformaÃ§Ãµes mais recentes
  - Contexto histÃ³rico
  - Tom jornalÃ­stico objetivo
  - OrganizaÃ§Ã£o cronolÃ³gica

## ğŸ”§ ConfiguraÃ§Ã£o do Modelo

```python
from agno.models.ollama import Ollama

model = Ollama(
    id="deepseek-r1:1.5b",
    host="http://matrix.o2pos.com.br:11434",
    provider="Ollama"
)
```

### ParÃ¢metros Importantes:

- **`id`**: Nome do modelo no Ollama
- **`host`**: EndereÃ§o do servidor Ollama
- **`provider`**: Identificador do provedor

## ğŸ› ï¸ Exemplo de Uso

### Agente Simples

```python
from agno.agent import Agent
from agno.models.ollama import Ollama

agent = Agent(
    name="Meu Agente",
    model=Ollama(
        id="deepseek-r1:1.5b",
        host="http://matrix.o2pos.com.br:11434"
    ),
    instructions=["Responda sempre em portuguÃªs brasileiro"]
)

response = agent.run("OlÃ¡! Como vocÃª estÃ¡?")
print(response)
```

### Agente com Ferramentas

```python
from agno.agent import Agent
from agno.models.ollama import Ollama
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    name="Agente Pesquisador",
    model=Ollama(
        id="deepseek-r1:1.5b",
        host="http://matrix.o2pos.com.br:11434"
    ),
    tools=[DuckDuckGoTools()],
    instructions=[
        "VocÃª Ã© um assistente de pesquisa",
        "Use as ferramentas disponÃ­veis",
        "Responda em portuguÃªs brasileiro"
    ]
)

response = agent.run("Busque informaÃ§Ãµes sobre inteligÃªncia artificial")
print(response)
```

## ğŸŒ URLs de Acesso

- **Interface Web**: http://localhost:3000
- **Playground Ollama**: http://localhost:7777 (via `playground_ollama.py`)
- **Servidor Ollama**: http://matrix.o2pos.com.br:11434

## ğŸ” Testes e VerificaÃ§Ã£o

### 1. **Teste de ConexÃ£o**

```bash
python test_ollama.py
```

### 2. **Verificar Modelos DisponÃ­veis**

```bash
curl http://matrix.o2pos.com.br:11434/api/tags
```

### 3. **Teste Direto do Modelo**

```bash
curl -X POST http://matrix.o2pos.com.br:11434/api/generate \
  -H "Content-Type: application/json" \
  -d '{
    "model": "deepseek-r1:1.5b",
    "prompt": "OlÃ¡! Responda em portuguÃªs."
  }'
```

## ğŸ¯ Casos de Uso

### 1. **Pesquisa AcadÃªmica**

- Busca de artigos cientÃ­ficos
- AnÃ¡lise de tendÃªncias
- Coleta de dados estatÃ­sticos

### 2. **AnÃ¡lise de Mercado**

- Pesquisa de concorrentes
- AnÃ¡lise de tendÃªncias
- Coleta de notÃ­cias do setor

### 3. **Jornalismo**

- VerificaÃ§Ã£o de fatos
- Coleta de informaÃ§Ãµes atualizadas
- AnÃ¡lise de contexto histÃ³rico

## âš ï¸ ConsideraÃ§Ãµes Importantes

### 1. **Performance**

- O modelo `deepseek-r1:1.5b` Ã© otimizado para velocidade
- Respostas podem ser mais rÃ¡pidas que modelos maiores
- Ideal para tarefas de pesquisa e anÃ¡lise

### 2. **LimitaÃ§Ãµes**

- Modelo menor pode ter limitaÃ§Ãµes em tarefas complexas
- DependÃªncia da conectividade com o servidor Ollama
- Necessidade de verificar disponibilidade do modelo

### 3. **SeguranÃ§a**

- Dados processados localmente no servidor Ollama
- Maior privacidade comparado a APIs externas
- Controle total sobre o ambiente de inferÃªncia

## ğŸ”§ SoluÃ§Ã£o de Problemas

### 1. **Erro de ConexÃ£o**

```bash
# Verificar se o servidor estÃ¡ acessÃ­vel
ping matrix.o2pos.com.br

# Testar porta
telnet matrix.o2pos.com.br 11434
```

### 2. **Modelo NÃ£o Encontrado**

```bash
# Listar modelos disponÃ­veis
curl http://matrix.o2pos.com.br:11434/api/tags

# Baixar modelo se necessÃ¡rio
curl -X POST http://matrix.o2pos.com.br:11434/api/pull \
  -H "Content-Type: application/json" \
  -d '{"name": "deepseek-r1:1.5b"}'
```

### 3. **Erro de Ferramentas**

- Verificar se `duckduckgo-search` estÃ¡ instalado
- Testar conectividade com internet
- Verificar se as ferramentas estÃ£o sendo importadas corretamente

## ğŸ“š Recursos Adicionais

- [DocumentaÃ§Ã£o Oficial do Agno - Ollama](https://docs.agno.com/models/ollama)
- [Exemplo de Agente Ollama](https://dineshr1493.medium.com/all-you-need-to-know-about-the-evolution-of-generative-ai-to-agentic-ai-part-9-agentic-ai-agno-74d74cd0d9f3)
- [Site Oficial do Ollama](https://ollama.com)

---

## ğŸ‰ Status: **PRONTO PARA USO!**

Seu setup Ollama com Agno estÃ¡ configurado e pronto para criar agentes de pesquisa poderosos! ğŸš€
